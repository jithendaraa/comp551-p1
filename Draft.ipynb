{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Experiments\" data-toc-modified-id=\"Experiments-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Experiments</a></span></li><li><span><a href=\"#Deliverables\" data-toc-modified-id=\"Deliverables-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Deliverables</a></span></li></ul></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Replace-with-Mode\" data-toc-modified-id=\"Replace-with-Mode-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Replace with Mode</a></span></li></ul></li><li><span><a href=\"#Remove-'-?'-in-workclass,-occupation,-native-country\" data-toc-modified-id=\"Remove-'-?'-in-workclass,-occupation,-native-country-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Remove ' ?' in workclass, occupation, native-country</a></span></li><li><span><a href=\"#Convert-Discrete-to-OneHot\" data-toc-modified-id=\"Convert-Discrete-to-OneHot-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Convert Discrete to OneHot</a></span></li><li><span><a href=\"#KNN-Classifiers\" data-toc-modified-id=\"KNN-Classifiers-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>KNN Classifiers</a></span></li><li><span><a href=\"#DecisionTreeClassifier\" data-toc-modified-id=\"DecisionTreeClassifier-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>DecisionTreeClassifier</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Your first task is to acquire the data, analyze it, and clean it (if necessary).  You will use two datasets in this project,outlined below.\n",
    "• Dataset 1 (Adult dataset): This dataset presents several attributes of different individuals and the predictiontask is to determine whether someone makes over 50K a year.  Download and read information about the datasethere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The essential subtasks for this part of the project include:\n",
    "\n",
    "1.  Download the datasets.Hints: For clarity, in the Adult dataset, adult.data contains the training/validation dataand adult.test contains the test data.\n",
    "2.  Load the datasets into Pandas dataframes or NumPy objects (i.e., arrays or matrices) in Python.\n",
    "3.  Clean the data.  You should remove instances that have too many missing or invalid data entries.\n",
    "4.  Convert discrete variables into multiple variables using one-hot encoding.  For an example on how to do this,check out ”Encoding categorical features” in the scikit-learn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "In this part, you will compare two supervised learning frameworks, namelyK-nearest neighbours(KNN) anddecisiontrees,  to predict whether the income of an adult exceeds $50K/yr.  A similar analysis should be performed for thesecond dataset.  The specific subtasks for this part include:\n",
    "1.  Implement and perform 5-fold cross validation on the training/validation data (for theAdultdataset, this datais contained in theadult.datafile) to optimize hyperparameters for both models.Your implementation forcross-validation should be from scratch.  You should not use existing packages for cross validation.Report the mean of the training and validation metrics for the given hyperparameters.\n",
    "2.  Sample growing subsets of the training/validation data and repeat step 1.  We want to understand how the sizeof a dataset impacts both the training and validation error.\n",
    "3.  Take the best performing model (the one with the best performance on 5-fold cross validation) and apply it onthe test set (in theAdultdataset, this is theadult.testfile).  This is an unbiased estimate of how your modelwould perform on new/unseen data.\n",
    "4.  [Optional] Go above and beyond!  Examples:  different normalization techniques or other ways of handling of missing data (search “data imputation” techniques).  Employ more sophisticated techniques for hyper-parameter search.  Engineering new features out of existing ones to get a better performance.  Investigate which featuresare the most useful (e.g., by correlating them with your predictions or removing them from your data)?\n",
    "5.  Analyze your findings; how did the choice of the various hyper-parameters impact generalization?  How aboutthe size of training data?  If any of these findings do not agree with your expectation, you can form hypothesesand further investigate them.\n",
    "\n",
    "## Deliverables\n",
    "You must submit two separate files to MyCourses(using the exact filenames and file types outlined below):\n",
    "\n",
    "1. code.zip:  Your  entire  code,  which  should  consist  of  a  jupyter  notebook  file  (.ipynb),  and  additional  pythonfiles (.py);the notebook should contain the main body of your code, where we can see and easily reproduce the plots in your report.\n",
    "2. writeup.pdf:  Your (max three pages) project write-up as a pdf (details below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the datasets.Hints: For clarity, in the Adult dataset, adult.data contains the training/validation data and adult.test contains the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:06.701732Z",
     "start_time": "2021-09-27T16:26:04.880374Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Vars\n",
    "data_rootdir = 'Adult dataset'\n",
    "remove_dup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:06.777719Z",
     "start_time": "2021-09-27T16:26:06.709400Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Put in .py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rootdir = 'Adult dataset'\n",
    "\n",
    "adult_names = [\"age\",\n",
    "\"workclass\",\n",
    "\"fnlwgt\",\n",
    "\"education\",\n",
    "\"education-num\",\n",
    "\"marital-status\",\n",
    "\"occupation\",\n",
    "\"relationship\",\n",
    "\"race\",\n",
    "\"sex\",\n",
    "\"capital-gain\",\n",
    "\"capital-loss\",\n",
    "\"hours-per-week\",\n",
    "\"native-country\"]\n",
    "\n",
    "def load_adult(rootdir=rootdir, split='train'):\n",
    "    csv_name = 'adult.data' if split == 'train' else 'adult.test'\n",
    "    csv_path = os.path.join(rootdir, csv_name)\n",
    "    assert os.path.exists(csv_path)\n",
    "    adult_data = pd.read_csv(csv_path, names=adult_names + ['salary'], index_col=False)\n",
    "    return adult_data\n",
    "\n",
    "def get_faulty_col_names(df):\n",
    "    faulty_cols = []\n",
    "    \n",
    "#     Check NA values\n",
    "    for col_name in df.columns.tolist():\n",
    "        if df[col_name].isna().values.any() is True:\n",
    "            faulty_cols.append(col_name)\n",
    "\n",
    "#     Check for ' ?'\n",
    "        if ' ?' in df[col_name].unique().tolist():\n",
    "            if col_name not in faulty_cols:\n",
    "                faulty_cols.append(col_name)\n",
    "            print(f\"Number of ' ?' in {col_name}: {df[col_name].value_counts()[' ?']}\")\n",
    "    \n",
    "    return faulty_cols\n",
    "\n",
    "def replace_with_mode(df, faulty_cols):\n",
    "    \n",
    "    df_without_QM = df.copy()\n",
    "    for col in faulty_cols:\n",
    "        df_without_QM = df_without_QM[getattr(df, col) != ' ?']\n",
    "    \n",
    "    r_df = df.copy()\n",
    "    mapping = {}\n",
    "    for col in faulty_cols:\n",
    "        mapping[col] = df_without_QM[col].mode().values[0]\n",
    "        r_df[col] = r_df[col].replace(' ?', mapping[col])\n",
    "    return r_df, mapping\n",
    "\n",
    "def replace_with_mapping(df, faulty_cols, mapping):\n",
    "    r_df = df.copy()\n",
    "    for col in faulty_cols:\n",
    "        r_df[col] = r_df[col].replace(' ?', mapping[col])\n",
    "    return r_df\n",
    "\n",
    "def get_binary_labels_for_salary(df):\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame()\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    salary_map = {' <=50K': 0, ' <=50K.': 0, ' >50K': 1, ' >50K.': 1}\n",
    "    df['salary'] = df['salary'].map(salary_map)\n",
    "    \n",
    "    return df['salary'].tolist()\n",
    "\n",
    "def generate_cross_validation(n_folds, X, y):\n",
    "    samples = len(X)\n",
    "    elements_in_fold = samples // n_folds\n",
    "    indices = [0]\n",
    "    while indices[-1] + elements_in_fold <= samples - samples % n_folds:\n",
    "        indices.append(indices[-1] + elements_in_fold)\n",
    "    indices[-1] = samples\n",
    "    cross_val_sets = [[indices[i], indices[i+1]] for i in range(len(indices)-1)]\n",
    "    for val_set in cross_val_sets:\n",
    "        begin, end = val_set[0], val_set[1]\n",
    "        train_X_fold = X[0:begin].append(X[end:])\n",
    "        validation_X_fold = X[begin:end]\n",
    "        train_y_fold = y[0:begin] + y[end:]\n",
    "        validation_y_fold = y[begin:end]\n",
    "        yield train_X_fold, train_y_fold, validation_X_fold, validation_y_fold\n",
    "\n",
    "def knn_fit(X_train, y_train, X_val, y_val, one_hot, knn=3):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=knn)\n",
    "    neigh.fit(one_hot.transform(X_train), y_train)\n",
    "    pred_y = neigh.predict(OH_enc.transform(X_val))\n",
    "    acc = get_accuracy(y_val, pred_y)\n",
    "    return neigh, acc\n",
    "\n",
    "def eval_classifier(X, y, one_hot, classifier):\n",
    "    pred_y = classifier.predict(one_hot.transform(X))\n",
    "    acc = get_accuracy(y, pred_y)\n",
    "    return acc\n",
    "\n",
    "def fit_classifier(X_train, y_train, X_val, y_val, one_hot, classifier_model, **kwargs):\n",
    "    classifier = classifier_model(**kwargs)\n",
    "    classifier.fit(one_hot.transform(X_train), y_train)\n",
    "    acc = eval_classifier(X_val, y_val, one_hot, classifier)\n",
    "    return classifier, acc\n",
    "\n",
    "def get_accuracy(y_label, y_pred):\n",
    "    assert len(y_label) == len(y_pred)\n",
    "    acc = 100 * sum(y_label == y_pred) / len(y_label)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the datasets into Pandas dataframes or NumPy objects (i.e., arrays or matrices) in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.332674Z",
     "start_time": "2021-09-27T16:26:06.784458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ' ?' in workclass: 1836\n",
      "Number of ' ?' in occupation: 1843\n",
      "Number of ' ?' in native-country: 582\n",
      "['workclass', 'occupation', 'native-country']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_adult(data_rootdir)\n",
    "\n",
    "if remove_dup is True:\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "# Get faulty columns in the df - ones with na values or ' :?' values\n",
    "faulty_cols = get_faulty_col_names(df)\n",
    "print(faulty_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faulty columns can be: \n",
    "1. Replaced with mode\n",
    "2. KNN imputed\n",
    "3. Retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.575421Z",
     "start_time": "2021-09-27T16:26:07.338046Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\anaconda3\\envs\\dreamerv2\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "clean_train_df, faulty_col_modes = replace_with_mode(df, faulty_cols)\n",
    "assert get_faulty_col_names(clean_train_df) == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.798163Z",
     "start_time": "2021-09-27T16:26:07.580069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\anaconda3\\envs\\dreamerv2\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32537\n"
     ]
    }
   ],
   "source": [
    "df_without_QM = df.copy()\n",
    "for col in faulty_cols:\n",
    "    df_without_QM = df_without_QM[getattr(df, col) != ' ?']\n",
    "\n",
    "mapping = {}\n",
    "for col in faulty_cols:\n",
    "    mapping[col] = df_without_QM[col].mode().values[0]\n",
    "\n",
    "clean_train_df = replace_with_mapping(df, faulty_cols, mapping)\n",
    "assert get_faulty_col_names(clean_train_df) == []\n",
    "print(len(clean_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove ' ?' in workclass, occupation, native-country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.806488Z",
     "start_time": "2021-09-27T16:26:07.802577Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = adult_data\n",
    "# print(len(df))\n",
    "# for col_name in col_names_with_nan:\n",
    "#     df = df[getattr(df, col_name) != ' ?']\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.833040Z",
     "start_time": "2021-09-27T16:26:07.816848Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.hist(figsize=(16, 16), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.847906Z",
     "start_time": "2021-09-27T16:26:07.842245Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['native-country'].value_counts().index\n",
    "# # df['native-country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.860843Z",
     "start_time": "2021-09-27T16:26:07.855007Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_cols = adult_data.select_dtypes(include=['object']).columns.tolist()\n",
    "# n = len(cat_cols)\n",
    "# ncols = 3\n",
    "# nrows = (n // ncols + 1) if n % ncols != 0 else (n // ncols)\n",
    "# plt.figure(figsize=(16 * nrows, 8 * ncols))\n",
    "# for idx, col in enumerate(cat_cols):\n",
    "# #     print(idx)\n",
    "# #     print(cat_cols)\n",
    "#     plt.subplot(nrows, ncols, idx  + 1)\n",
    "#     plt.grid()\n",
    "#     plt.bar(adult_data[col].value_counts().index, adult_data[col].value_counts().values)\n",
    "#     plt.title(col)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.875708Z",
     "start_time": "2021-09-27T16:26:07.868305Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# n = len(cat_cols)\n",
    "# ncols = 4\n",
    "# plt.figure(figsize=(16 * n // ncols, 4 * ncols))\n",
    "# for idx, col in enumerate(cat_cols):\n",
    "#     plt.subplot(n // ncols, ncols, idx  + 1)\n",
    "#     plt.bar( df[col].value_counts().index, df[col].value_counts().values)\n",
    "#     plt.title(col)\n",
    "#     plt.grid()\n",
    "#     # if idx >= 3: break\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Discrete to OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.920338Z",
     "start_time": "2021-09-27T16:26:07.883005Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = clean_train_df.drop('salary', axis=1), get_binary_labels_for_salary(clean_train_df['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:07.948230Z",
     "start_time": "2021-09-27T16:26:07.926596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Variables:  ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "# Get categorical variables\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Discrete Variables: \", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:11.687949Z",
     "start_time": "2021-09-27T16:26:07.956145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OH_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "OH_enc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:12.609200Z",
     "start_time": "2021-09-27T16:26:11.693762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:  16281\n",
      "Number of ' ?' in workclass: 963\n",
      "Number of ' ?' in occupation: 966\n",
      "Number of ' ?' in native-country: 274\n",
      "Columns to clean ['workclass', 'occupation', 'native-country']\n",
      "After cleaning:  16281\n"
     ]
    }
   ],
   "source": [
    "test_df = load_adult(data_rootdir, 'test')\n",
    "print(\"Before cleaning: \", len(test_df))\n",
    "faulty_test_cols = get_faulty_col_names(test_df)\n",
    "print(\"Columns to clean\", faulty_test_cols)\n",
    "\n",
    "clean_test_df = replace_with_mapping(test_df, faulty_test_cols, mapping)\n",
    "assert get_faulty_col_names(clean_test_df) == []\n",
    "print(\"After cleaning: \", len(clean_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:12.637872Z",
     "start_time": "2021-09-27T16:26:12.614091Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test = clean_test_df.drop('salary', axis=1), get_binary_labels_for_salary(clean_test_df['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters\n",
    "- `n_neighbors` : [2:10:2]\n",
    "- `p`: [1:2:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T16:26:04.955Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors=3\n",
    "knn_kw = {\n",
    "    'n_neighbors': n_neighbors,\n",
    "}\n",
    "neigh = KNeighborsClassifier(**knn_kw)\n",
    "neigh.fit(OH_enc.transform(X_train), y_train)\n",
    "\n",
    "print(\"Train Accuracy: \", eval_classifier(X_train, y_train, OH_enc, neigh))\n",
    "print(\"Test Accuracy: \", eval_classifier(X_test, y_test, OH_enc, neigh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T16:26:04.962Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "n_folds = 5\n",
    "models = []\n",
    "accs = []\n",
    "for batch in tqdm(generate_cross_validation(n_folds, X_train, y_train), total=n_folds):\n",
    "    cross_X_train, cross_y_train, cross_X_val, cross_y_val = batch\n",
    "    model, acc = fit_classifier(cross_X_train, cross_y_train, cross_X_val, cross_y_val, OH_enc, KNeighborsClassifier, **knn_kw)\n",
    "    models.append(model)\n",
    "    accs.append(acc)\n",
    "\n",
    "print(accs)\n",
    "print(f\"Model accuracy averaged across {n_folds} folds: {np.mean(accs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters\n",
    "- `criterion`: ['gini', 'entropy']\n",
    "- `max_depth`: [5:20:5]\n",
    "- `min_samples_split`: [2:6:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T16:26:04.972Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "criterion='entropy'\n",
    "max_depth=10\n",
    "dt_kw = {\n",
    "    'criterion': criterion,\n",
    "    'max_depth': max_depth,\n",
    "}\n",
    "classifier = DecisionTreeClassifier(**dt_kw)\n",
    "classifier.fit(OH_enc.transform(X_train), y_train)\n",
    "\n",
    "print(\"Train Accuracy: \", eval_classifier(X_train, y_train, OH_enc, classifier))\n",
    "print(\"Test Accuracy: \", eval_classifier(X_test, y_test, OH_enc, classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T16:26:04.978Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "n_folds = 5\n",
    "models = []\n",
    "accs = []\n",
    "for batch in tqdm(generate_cross_validation(n_folds, X_train, y_train), total=n_folds):\n",
    "    cross_X_train, cross_y_train, cross_X_val, cross_y_val = batch\n",
    "    model, acc = fit_classifier(cross_X_train, cross_y_train, cross_X_val, cross_y_val, OH_enc, DecisionTreeClassifier, **dt_kw)\n",
    "    models.append(model)\n",
    "    accs.append(acc)\n",
    "\n",
    "print(accs)\n",
    "print(f\"Model accuracy averaged across {n_folds} folds: {np.mean(accs)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0b0581b3519f14568f31e2916b59f2d0a9309dc2f5004ca75a3aec84761b849"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
